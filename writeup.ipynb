{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating Census Data with the ForkJoin Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#version: 0 = SimpleSequential, 1 = SimpleForkJoin, 2 = GridSequential, ...\n",
    "#action: 0 = reindex, 1 = query\n",
    "\n",
    "def speed_test(version, action, numReps, xRes, yRes, gran = 200):\n",
    "    cmd = ['java', 'PerformanceTester', str(version), str(action), str(numReps), str(xRes), str(yRes), str(gran)]\n",
    "    return float(subprocess.check_output(cmd)) / numReps / 1000 #lets use ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sanity_test(version, xRes, yRes):\n",
    "    cmd = ['java', 'SanityCheck', '0', '30', '30']\n",
    "    return subprocess.check_output(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'population for query (0,0,0,0) is 0\\npopulation for query (30,30,0,0) is 312471327\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sanity_test(0, 30, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleSequentialQuerySolver\n",
    "\n",
    "SimpleSequentialQuerySolver solves queries with time complexity $\\Theta(n)$ where n is the size of the census data set.  Before accepting queries, SimpleSequentialQuerySolver must find the corners of the smallest rectangle enclosing all census data points.  This operation also has time complexity $\\Theta(n)$.  Grid dimensions do not affect time complexity. On my macbook pro, finding the corners takes about 4500 ms and querying the population takes about 3200 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'population for query (0,0,0,0) is 0\\npopulation for query (30,30,0,0) is 312471327\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sanity check:\n",
    "sanity_test(1, 30, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SimpleForkJoinQuerySolver\n",
    "The simple ForkJoin query solver works similarly to the simple sequential query solver except it uses the ForkJoin framework to parallelize corner finding and querying.  This performance of SimpleSequentialQuerySolver depends on it's granularity, i.e. the largest chunk size that a single ForkJoin task will handle without forking.  To find the best granularity, we will simply test a few values and guess which granularity maximizes the performance of each operation. We shall begin with $granularity = 100$ since lower values (around 10) cause us to create too many tasks and run out of memory.\n",
    "\n",
    "There is a tradeoff between parallelism and task overhead which suggests a unimodal time / granularity curve (single global minimum at inflection point). Unfortunately, my macbook only has one core with hyperthreading (or possibly two cores without hyperthreading).  This prevents parallelism from having any benefit. We observe a minimum at $granularity = 250,000$ which is larger than the data size.  At this granularity, a single task executes sequentially.  There is no parallelism whatsoever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "granularity_test_points = [100, 500, 1000, 5000, 10000, 50000, 100000, 250000]\n",
    "index_times = [call_test(1, 0, 50, 3, 3, g) for g in granularity_test_points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Granularity': granularity_test_points,\n",
    "    'Index Time': index_times\n",
    "}\n",
    "\n",
    "dfrm = pd.DataFrame(data)\n",
    "\n",
    "seaborn.jointplot(x='Granularity', y='Index Time', data=dfrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GridSequentialQuerySolver\n",
    "\n",
    "GridSequentialQuerySolver builds a grid so that it may solve queries in constant time.  It must first build up a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
